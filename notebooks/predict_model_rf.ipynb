{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_tickers\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many days to predict\n",
    "PREDICT_PERIOD=128\n",
    "\n",
    "# the minimal number of data entries for a stock\n",
    "MIN_TOTAL_DATA_PER_STOCK = 1000\n",
    "MIN_TRAINING_DATA_PER_STOCK = 500\n",
    "MIN_TEST_DATA_PER_STOCK = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers('dax_40.txt') + get_tickers('ftse_100.txt') + get_tickers('sp_500.txt') + get_tickers('omx_30.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "# Assuming 'tickers' is your list of strings\n",
    "selected_tickers = random.sample(tickers, 10)\n",
    "\n",
    "#selected_tickers = tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re  # Regular expressions module\n",
    "\n",
    "# # Define the path to your file\n",
    "# file_path = 'data/recommended_gpt4.txt'\n",
    "\n",
    "# # Initialize an empty list to store ticker names\n",
    "# ticker_names = []\n",
    "\n",
    "# # Open and read the file\n",
    "# try:\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             # Use regular expression to find the ticker name in parentheses\n",
    "#             match = re.search(r'\\((.*?)\\)', line)\n",
    "#             if match:\n",
    "#                 # If a match is found, extract the ticker name and add it to the list\n",
    "#                 ticker_names.append(match.group(1))\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"The file at {file_path} was not found.\")\n",
    "\n",
    "# # Print the list of ticker names\n",
    "# print(ticker_names)\n",
    "# selected_tickers = ticker_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "\n",
    "#selected_tickers = random.sample(selected_tickers, 10)\n",
    "len(selected_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 128  # trading days in half year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "def nth_weekday_of_month(year, month, index, weekday):\n",
    "  \"\"\"\n",
    "  Find the nth occurrence of a specific weekday in a given month.\n",
    "\n",
    "  :param year: The year as an integer.\n",
    "  :param month: The month as an integer (1-12).\n",
    "  :param index: The index of the occurrence (1st, 2nd, 3rd, etc.)\n",
    "  :param weekday: The day of the week as an integer where Monday is 1 and Sunday is 7.\n",
    "  :return: The date of the nth weekday.\n",
    "  \"\"\"\n",
    "\n",
    "  weekday = weekday - 1\n",
    "  # Start at the beginning of the month\n",
    "  first_day_of_month = pd.Timestamp(year=year, month=month, day=1)\n",
    "  # Find the first occurrence of the specific weekday\n",
    "  first_weekday = first_day_of_month + timedelta(days=((weekday - first_day_of_month.weekday()) + 7) % 7)\n",
    "  \n",
    "  # Add (index - 1) weeks to the first occurrence of the weekday\n",
    "  nth_weekday = first_weekday + timedelta(weeks=index-1)\n",
    "  return nth_weekday.day\n",
    "\n",
    "def is_file_downloaded_recently(file_path, seconds=36000):\n",
    "  if not os.path.exists(file_path):\n",
    "    return False\n",
    "  file_age = time.time() - os.path.getmtime(file_path)\n",
    "  return file_age <= seconds\n",
    "\n",
    "def get_table_by_id_fred(id, path, n_features, \n",
    "                         start='1950-01-01', end=\"2024-01-01\", if_log=True):\n",
    "  print('start:', start, 'end:', end)\n",
    "  feature_columns = []\n",
    "  if path is None:\n",
    "    path = 'data/fred'\n",
    "\n",
    "  file_path = os.path.join(path, f'{id}.csv')\n",
    "  if not is_file_downloaded_recently(file_path):\n",
    "    print(f'Metric: {id} need to be refreshed...')\n",
    "    df = pdr.get_data_fred(id, start='1950-01-01', end=None)\n",
    "    df.to_csv(f'data/fred/{id}.csv')\n",
    "\n",
    "  df = pd.read_csv(os.path.join(path, f'{id}.csv'), index_col='DATE', parse_dates=True)\n",
    "  df = df[start:end]\n",
    "\n",
    "  if if_log:\n",
    "    df[f'log_{id}'] = np.log(df[id])\n",
    "\n",
    "  n_days = [int(2**n) for n in range(n_features)]\n",
    "  for n in n_days:\n",
    "    if if_log:\n",
    "      name = f'log_{id}_diff_{n}'\n",
    "      df[name] = df[f'log_{id}'] - df[f'log_{id}'].shift(n)\n",
    "    else:\n",
    "      name = f'{id}_diff_{n}'\n",
    "      df[name] = df[id] - df[id].shift(n)\n",
    "    feature_columns.append(name)\n",
    "  return df, feature_columns\n",
    "\n",
    "def merge_fred(df, id, n_features, start, end, release_week_index, release_week_day, if_log=True):\n",
    "  path = 'data/fred'\n",
    "  df_new, columns = get_table_by_id_fred(id, path, n_features, start=start, end=end, if_log=if_log)\n",
    "  print(f\"last update for {id}\", df_new.iloc[-1].name, df_new.iloc[-1][id])\n",
    "\n",
    "  def get_last_metric_date(row, release_week_index, release_week_day):\n",
    "    year = row.name.year\n",
    "    month = row.name.month\n",
    "    day = row.name.day\n",
    "\n",
    "    release_date = nth_weekday_of_month(year, month, release_week_index, release_week_day)\n",
    "    if day <= release_date:\n",
    "      if month == 1:\n",
    "        year -= 1\n",
    "        month = 11\n",
    "      elif month == 2:\n",
    "        year -= 1\n",
    "        month = 12\n",
    "      else:\n",
    "        month -= 2\n",
    "    else:\n",
    "      if month == 1:\n",
    "        year -= 1\n",
    "        month = 12\n",
    "      else:\n",
    "        month -= 1\n",
    "    \n",
    "    return pd.to_datetime(f\"{year}-{month}-01\")\n",
    "  \n",
    "  df['LAST_METRIC_DATE'] = df.apply(get_last_metric_date, axis=1, \n",
    "                                    args=(release_week_index, release_week_day))\n",
    "  \n",
    "  df = pd.merge_asof(df, df_new[columns], left_on='LAST_METRIC_DATE', right_index=True)\n",
    "  # delete the column 'LAST_METRIC_DATE'\n",
    "  df = df.drop(columns=['LAST_METRIC_DATE'])\n",
    "  return df, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(df, type='top'):\n",
    "  if type == 'top':\n",
    "    for i in range(len(df)):\n",
    "      if df.iloc[i].isnull().any() == False:\n",
    "        break\n",
    "    df_top = df[:i]\n",
    "    df = df[i:]\n",
    "\n",
    "    return df, df_top\n",
    "  \n",
    "  elif type == 'bottom':\n",
    "    for i in range(1, len(df)):\n",
    "      if df.iloc[-i].isnull().any() == False:\n",
    "        break\n",
    "    df_tail = df[-i:]\n",
    "    df = df[:-i]\n",
    "    return df, df_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, n_features):\n",
    "  feature_columns = []\n",
    "  for i in range(n_features):\n",
    "    n_days = 2**i\n",
    "\n",
    "    df[f'log_price_diff_{n_days}'] = np.log(df['Adj Close'].shift(n_days))/df['Adj Close']\n",
    "    #df[f'price_diff_{n_days}'] = pd.to_numeric(df[f'price_diff_{n_days}'], errors='coerce')\n",
    "    log_volume = np.log(df['Volume']+1e-8)\n",
    "    df[f'log_volume_diff_{n_days}'] = log_volume - log_volume.shift(n_days)\n",
    "    feature_columns.append(f'log_price_diff_{n_days}')\n",
    "    feature_columns.append(f'log_volume_diff_{n_days}')\n",
    "    #feature_columns.append(f'volume_diff_{n_days}')\n",
    "  return df, feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the stock suffixes to their base currencies\n",
    "currency_mapping = {\n",
    "  '.ST': 'SEK',\n",
    "  '.DE': 'EUR',\n",
    "  '.L': 'GBP'\n",
    "}\n",
    "\n",
    "# Map currency pairs to directions\n",
    "conversion_mapping = {\n",
    "  ('SEK', 'USD'): ('DEXSDUS', True),\n",
    "  ('EUR', 'USD'): ('DEXUSEU', False),\n",
    "  ('GBP', 'USD'): ('DEXUSUK', False),\n",
    "}\n",
    "\n",
    "\n",
    "def get_currency_pair(stock_suffix, base_currency):\n",
    "    stock_base_currency = currency_mapping.get(stock_suffix, 'USD')\n",
    "    if base_currency == stock_base_currency:\n",
    "        return None, None  # No conversion needed\n",
    "    else:\n",
    "        return conversion_mapping.get((stock_base_currency, base_currency))\n",
    "\n",
    "\n",
    "def read_and_filter_exchange_rates(exchange_name):\n",
    "  return read_and_filter(exchange_name, 'data/fred')\n",
    "\n",
    "def read_and_filter(name, path):\n",
    "  filepath = f'{path}/{name}.csv'\n",
    "  df = pd.read_csv(filepath, index_col='DATE', parse_dates=True)\n",
    "  return df\n",
    "\n",
    "def convert(df, exchange_name, inversion):\n",
    "  df_rate = read_and_filter_exchange_rates(exchange_name)\n",
    "  start = max(df.index[0], df_rate.index[0])\n",
    "  df = df[df.index >= start]\n",
    "  df_rate = df_rate[df_rate.index >= start]\n",
    "\n",
    "  df_rate = df_rate[[exchange_name]]\n",
    "  if inversion:\n",
    "    df_rate[exchange_name] = 1/df_rate[exchange_name]\n",
    "  df_merged = pd.merge_asof(df, df_rate, left_index=True, right_index=True, direction='nearest')\n",
    "  df_merged['Adj Close'] = df_merged['Adj Close'] * df_merged[exchange_name]\n",
    "  return df_merged[['Adj Close', 'Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_price_data(stock_name, start='1950-01-01'):\n",
    "  file_path = f'data/prices/{stock_name}.csv'\n",
    "  if not is_file_downloaded_recently(file_path):\n",
    "    data = pdr.get_data_yahoo(stock_name, start=start, end=None)\n",
    "    print('data downloaded:', data.head())\n",
    "    if len(data) > 100:\n",
    "      data.to_csv(file_path)\n",
    "    else:\n",
    "      print(f'Cannot download {stock_name}, using old data...')\n",
    "\n",
    "  df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_X_y_by_stock(stock_name, period, split_date='2018-01-01'):\n",
    "  print(f'processing {stock_name}...')\n",
    "  try:\n",
    "    df = load_latest_price_data(stock_name)\n",
    "  except FileNotFoundError:\n",
    "    print(f'Cannot find data for: {stock_name}')\n",
    "    return None, None, None, None\n",
    "  \n",
    "\n",
    "\n",
    "  print('initial size:', len(df))\n",
    "  if len(df) < MIN_TOTAL_DATA_PER_STOCK:\n",
    "    print(f'Cannot find enough data for: {stock_name}')\n",
    "    return None, None, None, None\n",
    "\n",
    "  stock_suffix = '.' + stock_name.split('.')[-1]\n",
    "  exchange_name, needs_inversion = get_currency_pair(stock_suffix, 'USD')\n",
    "  if exchange_name is not None:\n",
    "    df = convert(df, exchange_name, needs_inversion)\n",
    "    \n",
    "  if len(df) == 0:\n",
    "    print(f'empty table...')\n",
    "    return None, None, None, None\n",
    "\n",
    "  df, feature_columns = add_features(df, 10)\n",
    "  \n",
    "  # the predict is the log return of period days.\n",
    "  df['log_predict'] = np.log(df['Adj Close'].shift(-period) / df['Adj Close'])\n",
    "  print('log predict: ',  len(df['log_predict'].dropna()))\n",
    "\n",
    "  timestamp = df.index[0]\n",
    "  earliest_date = timestamp.strftime('%Y-%m-%d')\n",
    "  start = earliest_date\n",
    "  end = None\n",
    "\n",
    "\n",
    "\n",
    "  df, columns = merge_fred(df, 'M2SL', 6, start, end, 4, 2, if_log=True)\n",
    "  feature_columns += columns\n",
    "\n",
    "  \n",
    "  df, columns = merge_fred(df, 'UNRATE', 6, start, end, 1, 5, if_log=False)\n",
    "  feature_columns += columns\n",
    "\n",
    "  df, columns = merge_fred(df, 'FEDFUNDS', 6, start, end, 1, 5, if_log=False)\n",
    "  feature_columns += columns\n",
    "\n",
    "  print('before removing: ', len(df))\n",
    "  df, _ = remove_nan(df, type='top')\n",
    "  if len(df) < MIN_TOTAL_DATA_PER_STOCK:\n",
    "    print(f'Cannot find enough data for: {stock_name}')\n",
    "    return None, None, None, None\n",
    "  print('top removed, length: ', len(df))\n",
    "  df, _ = remove_nan(df, type='bottom')\n",
    "  if len(df) < MIN_TOTAL_DATA_PER_STOCK:\n",
    "    print(f'Cannot find enough data for: {stock_name}')\n",
    "    return None, None, None, None\n",
    "  \n",
    "  print('bottom removed, length: ', len(df))\n",
    "  df = df[feature_columns + ['log_predict']]\n",
    "  df.dropna(inplace=True)\n",
    "  print('dropna removed, final length:', len(df))\n",
    "  \n",
    "  if len(df) < MIN_TOTAL_DATA_PER_STOCK:\n",
    "    print(f'Cannot find enough data for: {stock_name}')\n",
    "    return None, None, None, None\n",
    "  \n",
    "  df_test = df[df.index >= split_date]\n",
    "  df_train = df[df.index < split_date]\n",
    "  if len(df_train) < MIN_TRAINING_DATA_PER_STOCK:\n",
    "    print(f'Cannot find enough training data for: {stock_name}')\n",
    "    return None, None, None, None\n",
    "  if len(df_test) < MIN_TEST_DATA_PER_STOCK:\n",
    "    print(f'Cannot find enough test data for: {stock_name}')\n",
    "    return None, None, None, None\n",
    "  df_train_X = df_train[feature_columns]\n",
    "  df_train_y = df_train[['log_predict']]\n",
    "  df_test_X = df_test[feature_columns]\n",
    "  df_test_y = df_test[['log_predict']]\n",
    "\n",
    "  return df_train_X, df_train_y, df_test_X, df_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_from_hist_average(df_X, df_y, window_size):\n",
    "  return ((df_X['log_price_diff_128'].rolling(window=window_size).mean()[window_size:] - df_y['log_predict'][window_size:])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:                 Open      High       Low     Close  Adj Close     Volume\n",
      "Date                                                                    \n",
      "1980-12-12  0.128348  0.128906  0.128348  0.128348   0.099058  469033600\n",
      "1980-12-15  0.122210  0.122210  0.121652  0.121652   0.093890  175884800\n",
      "1980-12-16  0.113281  0.113281  0.112723  0.112723   0.086999  105728000\n",
      "1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089152   86441600\n",
      "1980-12-18  0.118862  0.119420  0.118862  0.118862   0.091737   73449600\n",
      "initial size: 10944\n",
      "log predict:  10816\n",
      "start: 1980-12-12 end: None\n",
      "Metric: M2SL need to be refreshed...\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1980-12-12 end: None\n",
      "Metric: UNRATE need to be refreshed...\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1980-12-12 end: None\n",
      "Metric: FEDFUNDS need to be refreshed...\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  10944\n",
      "top removed, length:  10218\n",
      "bottom removed, length:  10089\n",
      "dropna removed, final length: 10089\n"
     ]
    }
   ],
   "source": [
    "df_train_X, df_train_y, df_test_X, df_test_y = get_X_y_by_stock('AAPL', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(selected_tickers, period):\n",
    "  df_train_X_all = []\n",
    "  df_train_y_all = []\n",
    "  df_test_X_all = []\n",
    "  df_test_y_all = []\n",
    "  mean_square_errors_1 = []\n",
    "  mean_square_errors_3 = []\n",
    "  mean_square_errors_5 = []\n",
    "  valid_tickers = []\n",
    "  for stock_name in selected_tickers:\n",
    "    df_train_X, df_train_y, df_test_X, df_test_y = get_X_y_by_stock(stock_name, period)\n",
    "    if df_train_X is None:\n",
    "      continue \n",
    "    \n",
    "\n",
    "    valid_tickers.append(stock_name)\n",
    "    df_train_X_all.append(df_train_X)\n",
    "    df_train_y_all.append(df_train_y)\n",
    "    df_test_X_all.append(df_test_X)\n",
    "    df_test_y_all.append(df_test_y)\n",
    "    \n",
    "    mse_1 = get_mse_from_hist_average(df_test_X, df_test_y, 1)\n",
    "    mse_3 = get_mse_from_hist_average(df_test_X, df_test_y, 3)\n",
    "    mse_5 = get_mse_from_hist_average(df_test_X, df_test_y, 5)\n",
    "\n",
    "    mean_square_errors_1.append(mse_1)\n",
    "    mean_square_errors_3.append(mse_3)\n",
    "    mean_square_errors_5.append(mse_5)\n",
    "\n",
    "  return valid_tickers, df_train_X_all, df_train_y_all, df_test_X_all, df_test_y_all, {'mse_1': mean_square_errors_1, 'mse_3': mean_square_errors_3, 'mse_5': mean_square_errors_5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing EVO.ST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:                  Open       High        Low      Close  Adj Close    Volume\n",
      "Date                                                                       \n",
      "2015-03-20  18.450001  19.049999  17.799999  17.950001  17.568878  19791765\n",
      "2015-03-23  18.100000  18.100000  17.450001  17.549999  17.177370   3763595\n",
      "2015-03-24  17.650000  18.400000  17.549999  18.200001  17.813568   4625530\n",
      "2015-03-25  18.350000  18.400000  18.049999  18.049999  17.666754   1037285\n",
      "2015-03-26  17.950001  18.400000  17.850000  18.400000  18.009319   1342585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: 2302\n",
      "log predict:  2019\n",
      "start: 2015-03-20 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 2015-03-20 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 2015-03-20 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  2302\n",
      "top removed, length:  1581\n",
      "bottom removed, length:  1452\n",
      "dropna removed, final length: 925\n",
      "Cannot find enough data for: EVO.ST\n",
      "processing RR.L...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:                   Open        High         Low       Close  Adj Close  Volume\n",
      "Date                                                                         \n",
      "1988-07-01  125.477501  125.477501  125.477501  125.477501  58.676826       0\n",
      "1988-07-04  126.442703  126.442703  126.442703  126.442703  59.128185       0\n",
      "1988-07-05  132.233994  132.233994  132.233994  132.233994  61.836353       0\n",
      "1988-07-06  132.233994  132.233994  132.233994  132.233994  61.836353       0\n",
      "1988-07-07  134.164398  134.164398  134.164398  134.164398  62.739063       0\n",
      "initial size: 9204\n",
      "log predict:  8489\n",
      "start: 1988-07-01 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1988-07-01 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1988-07-01 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  9204\n",
      "top removed, length:  8471\n",
      "bottom removed, length:  8342\n",
      "dropna removed, final length: 5570\n",
      "processing MUV2.DE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:                   Open        High         Low       Close  Adj Close  Volume\n",
      "Date                                                                         \n",
      "1998-06-24  221.389008  222.412003  220.494995  222.156006  90.203712   96200\n",
      "1998-06-25  222.794998  227.014008  221.645004  225.479996  91.553375  285000\n",
      "1998-06-26  225.608002  228.802994  224.201004  227.908005  92.539238  247400\n",
      "1998-06-29  228.292007  232.638000  227.781006  231.871002  94.148361  170200\n",
      "1998-06-30  235.194000  237.238998  224.981003  224.981003  91.350777  482600\n",
      "initial size: 6627\n",
      "log predict:  5955\n",
      "start: 1999-01-04 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1999-01-04 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1999-01-04 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  6489\n",
      "top removed, length:  5731\n",
      "bottom removed, length:  5602\n",
      "dropna removed, final length: 3750\n",
      "processing DVA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:              Open   High    Low  Close  Adj Close    Volume\n",
      "Date                                                       \n",
      "1995-10-31  3.475  4.200  3.475  4.075      4.075  15479500\n",
      "1995-11-01  3.900  3.950  3.875  3.900      3.900   3056500\n",
      "1995-11-02  3.950  4.225  3.900  4.175      4.175   1185500\n",
      "1995-11-03  4.175  4.225  3.850  4.000      4.000   1823500\n",
      "1995-11-06  3.975  4.000  3.875  3.900      3.900    339500\n",
      "initial size: 7181\n",
      "log predict:  7053\n",
      "start: 1995-10-31 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1995-10-31 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1995-10-31 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  7181\n",
      "top removed, length:  6469\n",
      "bottom removed, length:  6340\n",
      "dropna removed, final length: 6340\n",
      "processing CTAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:             Open      High       Low     Close  Adj Close   Volume\n",
      "Date                                                              \n",
      "1983-08-19   0.0  0.972222  0.951389  0.951389   0.667754  1996200\n",
      "1983-08-22   0.0  0.972222  0.958333  0.958333   0.672628  1621800\n",
      "1983-08-23   0.0  0.965278  0.958333  0.958333   0.672628  1972800\n",
      "1983-08-24   0.0  0.986111  0.965278  0.965278   0.677503   819000\n",
      "1983-08-25   0.0  1.000000  0.979167  0.979167   0.687251   347400\n",
      "initial size: 10265\n",
      "log predict:  10137\n",
      "start: 1983-08-19 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1983-08-19 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1983-08-19 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  10265\n",
      "top removed, length:  9546\n",
      "bottom removed, length:  9417\n",
      "dropna removed, final length: 9417\n",
      "processing CCL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:             Open     High     Low    Close  Adj Close    Volume\n",
      "Date                                                           \n",
      "1987-07-24   0.0  3.93750  3.8750  3.93750   1.935135  15566400\n",
      "1987-07-27   0.0  3.93750  3.8750  3.90625   1.919778   1931200\n",
      "1987-07-28   0.0  3.90625  3.8750  3.87500   1.904419   2074800\n",
      "1987-07-29   0.0  3.90625  3.8750  3.87500   1.904419   4930800\n",
      "1987-07-30   0.0  3.90625  3.8125  3.81250   1.873703   4654400\n",
      "initial size: 9273\n",
      "log predict:  9145\n",
      "start: 1987-07-24 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1987-07-24 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1987-07-24 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  9273\n",
      "top removed, length:  8557\n",
      "bottom removed, length:  8428\n",
      "dropna removed, final length: 8428\n",
      "processing ABT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:             Open      High       Low     Close  Adj Close   Volume\n",
      "Date                                                              \n",
      "1980-03-17   0.0  0.512028  0.497999  0.501506   0.199947  7513463\n",
      "1980-03-18   0.0  0.512028  0.494492  0.505013   0.201345  5303621\n",
      "1980-03-19   0.0  0.515535  0.503260  0.512028   0.204142  2523497\n",
      "1980-03-20   0.0  0.513781  0.499753  0.499753   0.199248  4654925\n",
      "1980-03-21   0.0  0.506767  0.499753  0.505013   0.201345  1333034\n",
      "initial size: 11132\n",
      "log predict:  11004\n",
      "start: 1980-03-17 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1980-03-17 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1980-03-17 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  11132\n",
      "top removed, length:  10408\n",
      "bottom removed, length:  10279\n",
      "dropna removed, final length: 10279\n",
      "processing PSON.L...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:                   Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "1988-07-01  310.200104  310.200104  310.200104  310.200104  109.490639       0\n",
      "1988-07-04  308.437408  308.437408  308.437408  308.437408  108.868454       0\n",
      "1988-07-05  307.115295  307.115295  307.115295  307.115295  108.401810       0\n",
      "1988-07-06  309.759399  309.759399  309.759399  309.759399  109.335098       0\n",
      "1988-07-07  318.132507  318.132507  318.132507  318.132507  112.290504       0\n",
      "initial size: 9204\n",
      "log predict:  8489\n",
      "start: 1988-07-01 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1988-07-01 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1988-07-01 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  9204\n",
      "top removed, length:  8471\n",
      "bottom removed, length:  8342\n",
      "dropna removed, final length: 5570\n",
      "processing SWKS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:                 Open      High       Low     Close  Adj Close  Volume\n",
      "Date                                                                 \n",
      "1984-09-07  6.083333  6.083333  6.041667  6.041667   5.140091   11400\n",
      "1984-09-10  6.041667  6.083333  5.833333  5.833333   4.962846    7500\n",
      "1984-09-11  5.833333  5.916667  5.791667  5.875000   4.998296   27000\n",
      "1984-09-12  5.791667  5.791667  5.583333  5.666667   4.821052    7800\n",
      "1984-09-13  5.666667  5.666667  5.583333  5.666667   4.821052   10500\n",
      "initial size: 9999\n",
      "log predict:  9871\n",
      "start: 1984-09-07 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 1984-09-07 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 1984-09-07 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  9999\n",
      "top removed, length:  9270\n",
      "bottom removed, length:  9141\n",
      "dropna removed, final length: 9141\n",
      "processing ITRK.L...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded:              Open   High    Low  Close   Adj Close    Volume\n",
      "Date                                                        \n",
      "2002-05-24  425.0  435.0  418.0  433.5  298.500793  20207478\n",
      "2002-05-27  440.0  453.0  430.0  437.5  301.254974   7452852\n",
      "2002-05-28  438.0  440.0  433.0  437.0  300.910797   1541332\n",
      "2002-05-29  438.0  439.0  435.0  437.5  301.254974   1835850\n",
      "2002-05-30  436.0  439.0  435.0  437.0  300.910797    452620\n",
      "initial size: 5578\n",
      "log predict:  5116\n",
      "start: 2002-05-24 end: None\n",
      "last update for M2SL 2024-03-01 00:00:00 20841.2\n",
      "start: 2002-05-24 end: None\n",
      "last update for UNRATE 2024-04-01 00:00:00 3.9\n",
      "start: 2002-05-24 end: None\n",
      "last update for FEDFUNDS 2024-04-01 00:00:00 5.33\n",
      "before removing:  5578\n",
      "top removed, length:  4840\n",
      "bottom removed, length:  4711\n",
      "dropna removed, final length: 3255\n"
     ]
    }
   ],
   "source": [
    "valid_tickers, df_train_X_all, df_train_y_all, df_test_X_all, df_test_y_all, mses = get_X_y(selected_tickers, PREDICT_PERIOD)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now setup the random forest to work on these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 05:09:03,309] A new study created in memory with name: no-name-50e2d176-f232-4c6d-b594-70f222fb002d\n",
      "[I 2024-05-11 05:09:09,295] Trial 0 finished with value: 0.08388885560203668 and parameters: {'k': 11, 'n_estimators': 35, 'max_depth': 37, 'min_samples_split': 11, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'max_leaf_nodes': 41}. Best is trial 0 with value: 0.08388885560203668.\n",
      "[I 2024-05-11 05:09:17,943] Trial 1 finished with value: 0.08152274143975896 and parameters: {'k': 25, 'n_estimators': 81, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True, 'max_leaf_nodes': 39}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:09:23,665] Trial 2 finished with value: 0.08534389163394744 and parameters: {'k': 12, 'n_estimators': 33, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'max_leaf_nodes': 133}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:10:18,834] Trial 3 finished with value: 0.11099346266700977 and parameters: {'k': 18, 'n_estimators': 95, 'max_depth': 39, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'max_leaf_nodes': 35}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:10:28,643] Trial 4 finished with value: 0.0851224156316443 and parameters: {'k': 12, 'n_estimators': 58, 'max_depth': 40, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'max_leaf_nodes': 131}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:11:17,283] Trial 5 finished with value: 0.11502218763270984 and parameters: {'k': 16, 'n_estimators': 77, 'max_depth': 49, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False, 'max_leaf_nodes': 103}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:12:07,523] Trial 6 finished with value: 0.11663710932362766 and parameters: {'k': 17, 'n_estimators': 70, 'max_depth': 44, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': None, 'bootstrap': False, 'max_leaf_nodes': 192}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:13:19,981] Trial 7 finished with value: 0.12097585110621918 and parameters: {'k': 23, 'n_estimators': 90, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': False, 'max_leaf_nodes': 134}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:14:15,599] Trial 8 finished with value: 0.08605013817832208 and parameters: {'k': 29, 'n_estimators': 81, 'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True, 'max_leaf_nodes': 109}. Best is trial 1 with value: 0.08152274143975896.\n",
      "[I 2024-05-11 05:14:23,542] Trial 9 finished with value: 0.09064964845800541 and parameters: {'k': 8, 'n_estimators': 45, 'max_depth': 20, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False, 'max_leaf_nodes': 137}. Best is trial 1 with value: 0.08152274143975896.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from safeRegressors import SafeRandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import optuna\n",
    "\n",
    "n_trails = 10\n",
    "np.random.seed(42)\n",
    "def objective(trial):\n",
    "  # Define the hyperparameter configuration space\n",
    "  k = trial.suggest_int('k', 5, len(df_train_X_all[0].columns))\n",
    "  n_estimators = trial.suggest_int('n_estimators', 20, 100)\n",
    "  max_depth = trial.suggest_int('max_depth', 10, 50)\n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "  max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "  bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "  max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 10, 200)\n",
    "\n",
    "\n",
    "  # Model setup\n",
    "  model = SafeRandomForestRegressor(\n",
    "      n_estimators=n_estimators,\n",
    "      max_depth=max_depth,\n",
    "      min_samples_split=min_samples_split,\n",
    "      min_samples_leaf=min_samples_leaf,\n",
    "      max_features=max_features,\n",
    "      bootstrap=bootstrap,\n",
    "      max_leaf_nodes=max_leaf_nodes\n",
    "  )\n",
    "\n",
    "  pipeline = Pipeline([\n",
    "      ('truncate', SelectKBest(f_regression, k=k)), # Adjust 'k' as needed\n",
    "      ('regress', model),\n",
    "  ])\n",
    "\n",
    "  total_mses = 0\n",
    "  for i in range(len(valid_tickers)):\n",
    "\n",
    "    df_train_X = df_train_X_all[i]\n",
    "    df_train_y = df_train_y_all[i]\n",
    "\n",
    "    X_train = df_train_X.copy().values\n",
    "    y_train = df_train_y.copy().values.ravel()\n",
    "\n",
    "    predictions = cross_val_predict(pipeline, X_train, y_train, cv=5, n_jobs=5)\n",
    "\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    total_mses += mse\n",
    "  \n",
    "  return total_mses/len(valid_tickers)\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=n_trails) # Adjust the number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_value = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-13 05:42:28,966] A new study created in memory with name: no-name-f72b1599-53dd-4a74-9510-74d049af469f\n",
      "[I 2024-05-13 05:42:30,146] Trial 0 finished with value: 0.4464252961345192 and parameters: {'k': 24}. Best is trial 0 with value: 0.4464252961345192.\n",
      "[I 2024-05-13 05:42:31,222] Trial 1 finished with value: 0.39407617129372857 and parameters: {'k': 33}. Best is trial 1 with value: 0.39407617129372857.\n",
      "[I 2024-05-13 05:42:32,272] Trial 2 finished with value: 0.23069184227058756 and parameters: {'k': 17}. Best is trial 2 with value: 0.23069184227058756.\n",
      "[I 2024-05-13 05:42:33,475] Trial 3 finished with value: 0.3977561640567499 and parameters: {'k': 37}. Best is trial 2 with value: 0.23069184227058756.\n",
      "[I 2024-05-13 05:42:34,585] Trial 4 finished with value: 0.16039961343311454 and parameters: {'k': 15}. Best is trial 4 with value: 0.16039961343311454.\n",
      "[I 2024-05-13 05:42:35,681] Trial 5 finished with value: 0.39587769206750495 and parameters: {'k': 19}. Best is trial 4 with value: 0.16039961343311454.\n",
      "[I 2024-05-13 05:42:36,711] Trial 6 finished with value: 0.444556196305354 and parameters: {'k': 27}. Best is trial 4 with value: 0.16039961343311454.\n",
      "[I 2024-05-13 05:42:37,796] Trial 7 finished with value: 0.16039961343311454 and parameters: {'k': 15}. Best is trial 4 with value: 0.16039961343311454.\n",
      "[I 2024-05-13 05:42:38,919] Trial 8 finished with value: 0.38947041436043556 and parameters: {'k': 20}. Best is trial 4 with value: 0.16039961343311454.\n",
      "[I 2024-05-13 05:42:40,019] Trial 9 finished with value: 0.23069184227058756 and parameters: {'k': 17}. Best is trial 4 with value: 0.16039961343311454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the test error on RR.L\n",
      "Test RR.L MSE: 0.16458332700865694\n",
      "Computing the test error on MUV2.DE\n",
      "Test MUV2.DE MSE: 0.05431609453560986\n",
      "Computing the test error on DVA\n",
      "Test DVA MSE: 0.3556211329895668\n",
      "Computing the test error on CTAS\n",
      "Test CTAS MSE: 0.03322588917788992\n",
      "Computing the test error on CCL\n",
      "Test CCL MSE: 0.2619492022882175\n",
      "Computing the test error on ABT\n",
      "Test ABT MSE: 0.040380614698109586\n",
      "Computing the test error on PSON.L\n",
      "Test PSON.L MSE: 0.04385132444418098\n",
      "Computing the test error on SWKS\n",
      "Test SWKS MSE: 0.08098296764813076\n",
      "Computing the test error on ITRK.L\n",
      "Test ITRK.L MSE: 0.1313057625915713\n",
      "average mse: 0.12957959059799262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def objective_linear(trial):\n",
    "  # Define the hyperparameter configuration space\n",
    "  k = trial.suggest_int('k', 5, len(df_train_X_all[0].columns))\n",
    "  # Model setup\n",
    "  model = LinearRegression()\n",
    "\n",
    "  pipeline = Pipeline([\n",
    "      ('truncate', SelectKBest(f_regression, k=k)), # Adjust 'k' as needed\n",
    "      ('regress', model),\n",
    "  ])\n",
    "\n",
    "  total_mses = 0\n",
    "  for i in range(len(valid_tickers)):\n",
    "\n",
    "    df_train_X = df_train_X_all[i]\n",
    "    df_train_y = df_train_y_all[i]\n",
    "\n",
    "    X_train = df_train_X.copy().values\n",
    "    y_train = df_train_y.copy().values.ravel()\n",
    "\n",
    "    predictions = cross_val_predict(pipeline, X_train, y_train, cv=5, n_jobs=5)\n",
    "\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    total_mses += mse\n",
    "  \n",
    "  return total_mses/len(valid_tickers)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_linear, n_trials=n_trails) # Adjust the number of trials\n",
    "\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "best_params = study.best_params\n",
    "# rebuild the pipeline\n",
    "best_pipeline = Pipeline([\n",
    "        ('truncate', SelectKBest(f_regression, k=best_params['k'])), # Adjust 'k' as needed\n",
    "        ('regress', LinearRegression())])\n",
    "\n",
    "mses = []\n",
    "all_errors = None\n",
    "\n",
    "for i in range(len(valid_tickers)):\n",
    "#for i in range(10):\n",
    "  stock_name = valid_tickers[i]\n",
    "  print(f'Computing the test error on {stock_name}')\n",
    "  df_train_X = df_train_X_all[i]\n",
    "  df_train_y = df_train_y_all[i]\n",
    "  df_test_X = df_test_X_all[i]\n",
    "  df_test_y = df_test_y_all[i]\n",
    "\n",
    "  X_train = df_train_X.copy().values\n",
    "  y_train = df_train_y.copy().values.ravel()\n",
    "  X_test = df_test_X.copy().values\n",
    "  y_test = df_test_y.copy().values.ravel()\n",
    "\n",
    "  best_pipeline.fit(X_train, y_train)\n",
    "  y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  print(f'Test {valid_tickers[i]} MSE: {mse}')\n",
    "  mses.append(mse)\n",
    "\n",
    "print('average mse:', np.mean(mses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException\n",
    "\n",
    "\n",
    "class SafeSVR1(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, C, kernel, gamma, epsilon, timeout):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.timeout = timeout\n",
    "\n",
    "    def _create_svr(self):\n",
    "        return SVR(C=self.C, kernel=self.kernel, gamma=self.gamma, \n",
    "            epsilon=self.epsilon)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.svr = self._create_svr()\n",
    "\n",
    "        # Setting timeout signal\n",
    "        signal.signal(signal.SIGALRM, timeout_handler)\n",
    "        signal.alarm(self.timeout)\n",
    "        try:\n",
    "            self.svr.fit(X, y)\n",
    "            signal.alarm(0)\n",
    "        except TimeoutException:\n",
    "            raise TimeoutException(\"Fitting has been interrupted due to timeout.\")\n",
    "        except LinAlgError:\n",
    "            print(\"LinAlgError encountered. Using a default SVR model.\")\n",
    "            self.C = 1.0\n",
    "            self.kernel = 'rbf'\n",
    "            self.gamma = 'scale'\n",
    "            self.svr = self._create_svr()\n",
    "            self.svr.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.svr.predict(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'C': self.C, 'kernel': self.kernel, \n",
    "            'gamma': self.gamma, 'epsilon': self.epsilon, 'timeout': self.timeout}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        self.svr = self._create_svr()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-13 15:21:01,121] A new study created in memory with name: no-name-0c9157ab-0042-4497-a24c-b42c44fb1303\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:04,928] Trial 0 finished with value: 0.0925047631110297 and parameters: {'k': 5, 'C': 39.88450012707771, 'epsilon': 4.368025503960016, 'kernel': 'linear', 'gamma': 0.06866957423243873}. Best is trial 0 with value: 0.0925047631110297.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:40,198] Trial 1 finished with value: 0.11499852128901678 and parameters: {'k': 10, 'C': 0.8359785966385521, 'epsilon': 0.078909081981943, 'kernel': 'linear', 'gamma': 1.454852603147292}. Best is trial 0 with value: 0.0925047631110297.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:41,276] Trial 2 finished with value: 0.08066521389345895 and parameters: {'k': 19, 'C': 0.03584138142484681, 'epsilon': 1.055416903389878, 'kernel': 'rbf', 'gamma': 0.04473762398220559}. Best is trial 2 with value: 0.08066521389345895.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:42,288] Trial 3 finished with value: 0.09250476311102972 and parameters: {'k': 30, 'C': 0.012048094025260726, 'epsilon': 2.2647149513306153, 'kernel': 'rbf', 'gamma': 0.00011456871054641877}. Best is trial 2 with value: 0.08066521389345895.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:43,345] Trial 4 finished with value: 0.08067564278127592 and parameters: {'k': 7, 'C': 0.0870074491421367, 'epsilon': 1.0784403379878413, 'kernel': 'poly', 'gamma': 0.006976800589908352}. Best is trial 2 with value: 0.08066521389345895.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:44,360] Trial 5 finished with value: 0.09250476311102969 and parameters: {'k': 22, 'C': 41.918490104678696, 'epsilon': 8.650706124425309, 'kernel': 'linear', 'gamma': 0.03149867572076518}. Best is trial 2 with value: 0.08066521389345895.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:45,397] Trial 6 finished with value: 0.08753979552223169 and parameters: {'k': 26, 'C': 0.009050858534292067, 'epsilon': 1.3617625648895793, 'kernel': 'sigmoid', 'gamma': 0.0003036644510262785}. Best is trial 2 with value: 0.08066521389345895.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:21:52,350] Trial 7 finished with value: 0.07942726287127168 and parameters: {'k': 17, 'C': 0.38758983629420196, 'epsilon': 0.1690748141059693, 'kernel': 'rbf', 'gamma': 0.004214774712121266}. Best is trial 7 with value: 0.07942726287127168.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:22:29,524] Trial 8 finished with value: inf and parameters: {'k': 12, 'C': 51.02088402960921, 'epsilon': 0.09630940775921797, 'kernel': 'poly', 'gamma': 0.020635450744987103}. Best is trial 7 with value: 0.07942726287127168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A timeout has occurred during model fitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:22:33,460] Trial 9 finished with value: 0.09061869286870179 and parameters: {'k': 38, 'C': 0.028574895104145796, 'epsilon': 1.5490189225450646, 'kernel': 'sigmoid', 'gamma': 0.009309569338683127}. Best is trial 7 with value: 0.07942726287127168.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:22:52,591] Trial 10 finished with value: 0.06207419112892275 and parameters: {'k': 16, 'C': 0.0013331966258378703, 'epsilon': 0.0047286318718840785, 'kernel': 'rbf', 'gamma': 0.0010558172198486429}. Best is trial 10 with value: 0.06207419112892275.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:23:11,692] Trial 11 finished with value: 0.07434897823037595 and parameters: {'k': 16, 'C': 0.539454216039364, 'epsilon': 0.002293719076721195, 'kernel': 'rbf', 'gamma': 0.0011641497089992683}. Best is trial 10 with value: 0.06207419112892275.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:23:30,206] Trial 12 finished with value: 0.06209869669051403 and parameters: {'k': 15, 'C': 0.0010266083132233123, 'epsilon': 0.0015137756830455916, 'kernel': 'rbf', 'gamma': 0.0008292665521964311}. Best is trial 10 with value: 0.06207419112892275.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:23:48,561] Trial 13 finished with value: 0.062074545877892885 and parameters: {'k': 15, 'C': 0.0010930319053728769, 'epsilon': 0.0010455324263882687, 'kernel': 'rbf', 'gamma': 0.001071849157352131}. Best is trial 10 with value: 0.06207419112892275.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:24:10,352] Trial 14 finished with value: 0.06220741111771561 and parameters: {'k': 24, 'C': 0.0011819188629058073, 'epsilon': 0.004682631120590256, 'kernel': 'rbf', 'gamma': 0.00011842157293854704}. Best is trial 10 with value: 0.06207419112892275.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:24:28,951] Trial 15 finished with value: 0.06214997284031324 and parameters: {'k': 12, 'C': 0.00273845540907598, 'epsilon': 0.007652803241519073, 'kernel': 'rbf', 'gamma': 0.0011440681415870874}. Best is trial 10 with value: 0.06207419112892275.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:24:52,013] Trial 16 finished with value: 0.06218614677509157 and parameters: {'k': 28, 'C': 0.0036235759455211826, 'epsilon': 0.001224841947187172, 'kernel': 'rbf', 'gamma': 0.0021444351232248683}. Best is trial 10 with value: 0.06207419112892275.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:25:14,878] Trial 17 finished with value: 0.06183469522496786 and parameters: {'k': 33, 'C': 0.004325148419978019, 'epsilon': 0.012400851987631283, 'kernel': 'sigmoid', 'gamma': 0.0005419178401649985}. Best is trial 17 with value: 0.06183469522496786.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:25:38,822] Trial 18 finished with value: 0.06177415508319376 and parameters: {'k': 34, 'C': 0.004682508887507639, 'epsilon': 0.009968384128012918, 'kernel': 'sigmoid', 'gamma': 0.0005384997345504685}. Best is trial 18 with value: 0.06177415508319376.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:26:01,780] Trial 19 finished with value: 0.06190673677532742 and parameters: {'k': 36, 'C': 0.006258247991616071, 'epsilon': 0.018972604610077944, 'kernel': 'sigmoid', 'gamma': 0.00025226314336094943}. Best is trial 18 with value: 0.06177415508319376.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:26:22,731] Trial 20 finished with value: 0.0667092751041146 and parameters: {'k': 32, 'C': 0.10616509027835648, 'epsilon': 0.02009351170867378, 'kernel': 'sigmoid', 'gamma': 0.0002811190054696294}. Best is trial 18 with value: 0.06177415508319376.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:26:46,174] Trial 21 finished with value: 0.06176293215888197 and parameters: {'k': 37, 'C': 0.006381243202418643, 'epsilon': 0.01775726947415056, 'kernel': 'sigmoid', 'gamma': 0.00035634672045608775}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:27:07,589] Trial 22 finished with value: 0.06179696192595251 and parameters: {'k': 34, 'C': 0.005355570630940483, 'epsilon': 0.023135988030635712, 'kernel': 'sigmoid', 'gamma': 0.0004750626776907396}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:27:26,762] Trial 23 finished with value: 0.21610232416030206 and parameters: {'k': 35, 'C': 0.015094578252502235, 'epsilon': 0.0511173049601506, 'kernel': 'sigmoid', 'gamma': 0.003015049375443631}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:27:47,703] Trial 24 finished with value: 0.06205113676669373 and parameters: {'k': 38, 'C': 0.0052850474262069146, 'epsilon': 0.03420884687962704, 'kernel': 'sigmoid', 'gamma': 0.0001211849312471901}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:28:13,208] Trial 25 finished with value: 0.06193062465706748 and parameters: {'k': 31, 'C': 0.018880361074423632, 'epsilon': 0.009018496109360978, 'kernel': 'sigmoid', 'gamma': 0.0004690209707333659}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:28:33,732] Trial 26 finished with value: 0.06241134276586677 and parameters: {'k': 34, 'C': 0.002631840727082484, 'epsilon': 0.029901346262406304, 'kernel': 'sigmoid', 'gamma': 0.0026438607295163844}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:28:43,757] Trial 27 finished with value: 0.061839628792163634 and parameters: {'k': 28, 'C': 0.008988342319654806, 'epsilon': 0.17402650332402506, 'kernel': 'sigmoid', 'gamma': 0.00025859815743593356}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:28:58,895] Trial 28 finished with value: 0.06248617447502328 and parameters: {'k': 37, 'C': 0.0529538190925674, 'epsilon': 0.013798220433472662, 'kernel': 'poly', 'gamma': 0.00043616937901935543}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:30:08,284] Trial 29 finished with value: 0.14408444139632604 and parameters: {'k': 29, 'C': 0.14617642827792712, 'epsilon': 0.0034158206388752166, 'kernel': 'linear', 'gamma': 0.010343009927790862}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:30:38,353] Trial 30 finished with value: 46.29632154126222 and parameters: {'k': 34, 'C': 0.025249965370198097, 'epsilon': 0.006485334915839514, 'kernel': 'sigmoid', 'gamma': 0.11145351239964728}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:31:00,762] Trial 31 finished with value: 0.06182635147093721 and parameters: {'k': 33, 'C': 0.004493131927526587, 'epsilon': 0.012107841196811995, 'kernel': 'sigmoid', 'gamma': 0.0005397424270874491}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:31:22,139] Trial 32 finished with value: 0.06189021756586894 and parameters: {'k': 32, 'C': 0.0025629502434648464, 'epsilon': 0.011708257240241826, 'kernel': 'sigmoid', 'gamma': 0.0018669137050374043}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:31:43,484] Trial 33 finished with value: 0.06212552016104119 and parameters: {'k': 36, 'C': 0.010063835889855372, 'epsilon': 0.026394478013697768, 'kernel': 'sigmoid', 'gamma': 0.0005209429695909885}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:32:02,815] Trial 34 finished with value: 0.10125258173039536 and parameters: {'k': 27, 'C': 1.169451638097881, 'epsilon': 0.05437820410832583, 'kernel': 'sigmoid', 'gamma': 0.00023684952649619362}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:32:20,234] Trial 35 finished with value: 0.08880167986590665 and parameters: {'k': 25, 'C': 0.01640728721984892, 'epsilon': 0.017622707458780824, 'kernel': 'linear', 'gamma': 0.00015659742047466265}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:32:46,141] Trial 36 finished with value: 0.06996740385330497 and parameters: {'k': 30, 'C': 0.04463635602458272, 'epsilon': 0.0027378396020429976, 'kernel': 'sigmoid', 'gamma': 0.000641748659804788}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:33:00,996] Trial 37 finished with value: 0.062316792151659146 and parameters: {'k': 35, 'C': 0.0061240915006788525, 'epsilon': 0.005318812103887694, 'kernel': 'poly', 'gamma': 0.00010056539725699267}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:33:24,405] Trial 38 finished with value: 0.061950713549012194 and parameters: {'k': 22, 'C': 0.0022875336618403373, 'epsilon': 0.009237987131279511, 'kernel': 'sigmoid', 'gamma': 0.0017435691748732582}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:33:33,853] Trial 39 finished with value: 0.0700014986320646 and parameters: {'k': 5, 'C': 0.009649893294087804, 'epsilon': 0.04363619726720615, 'kernel': 'linear', 'gamma': 0.0001848983100782327}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:33:52,128] Trial 40 finished with value: 0.07347272327252433 and parameters: {'k': 31, 'C': 0.004552501297260835, 'epsilon': 0.07768486274483287, 'kernel': 'sigmoid', 'gamma': 0.005146124982544363}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:34:15,084] Trial 41 finished with value: 0.06202801149488037 and parameters: {'k': 34, 'C': 0.0018890144951362608, 'epsilon': 0.013939629548102947, 'kernel': 'sigmoid', 'gamma': 0.0004532240071363767}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:34:38,606] Trial 42 finished with value: 0.061794359019630075 and parameters: {'k': 33, 'C': 0.0038992764816242107, 'epsilon': 0.010612975110419573, 'kernel': 'sigmoid', 'gamma': 0.0007280455898152316}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:35:01,525] Trial 43 finished with value: 0.06329692255093708 and parameters: {'k': 38, 'C': 0.007674515945845423, 'epsilon': 0.028735200107830497, 'kernel': 'sigmoid', 'gamma': 0.00077547682119166}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:35:25,156] Trial 44 finished with value: 0.06193952659721681 and parameters: {'k': 36, 'C': 0.015499611152902729, 'epsilon': 0.007678378723787616, 'kernel': 'sigmoid', 'gamma': 0.00036163561548884654}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:35:40,259] Trial 45 finished with value: 0.062408240057119646 and parameters: {'k': 33, 'C': 0.0017597903286764606, 'epsilon': 0.004553875508041389, 'kernel': 'poly', 'gamma': 0.001397171591460031}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:36:04,565] Trial 46 finished with value: 0.06179779000601666 and parameters: {'k': 30, 'C': 0.004686635677612519, 'epsilon': 0.018288630567954607, 'kernel': 'sigmoid', 'gamma': 0.0007613079211926888}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n",
      "[I 2024-05-13 15:36:28,672] Trial 47 finished with value: 0.062081633558693415 and parameters: {'k': 31, 'C': 0.003281759881653493, 'epsilon': 0.02164274939222758, 'kernel': 'sigmoid', 'gamma': 0.00017130564660781944}. Best is trial 21 with value: 0.06176293215888197.\n",
      "/tmp/ipykernel_3693607/449106689.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
      "/tmp/ipykernel_3693607/449106689.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  epsilon = trial.suggest_loguniform('epsilon', 1e-3, 1e1)\n",
      "/tmp/ipykernel_3693607/449106689.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  gamma = trial.suggest_loguniform('gamma', 1e-4, 1e1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "\n",
    "import signal\n",
    "\n",
    "\n",
    "def objective_svm(trial):\n",
    "  # Define the hyperparameter configuration space\n",
    "  k = trial.suggest_int('k', 5, len(df_train_X_all[0].columns))\n",
    "  C = trial.suggest_float('C', 1e-3, 1e2,log=True)\n",
    "  epsilon = trial.suggest_float('epsilon', 1e-3, 1e1, log=True)\n",
    "  kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "  gamma = trial.suggest_float('gamma', 1e-4, 1e1, log=True)\n",
    "\n",
    "  # Model setup\n",
    "  model = SafeSVR1(C=C,  kernel=kernel, gamma=gamma, epsilon=epsilon, timeout=60)\n",
    "\n",
    "  pipeline = Pipeline([\n",
    "      ('truncate', SelectKBest(f_regression, k=k)), # Adjust 'k' as needed\n",
    "      ('svr', model),\n",
    "  ])\n",
    "\n",
    "  total_mses = 0\n",
    "  try:\n",
    "    for i in range(len(valid_tickers)):\n",
    "\n",
    "      df_train_X = df_train_X_all[i]\n",
    "      df_train_y = df_train_y_all[i]\n",
    "\n",
    "      X_train = df_train_X.copy().values\n",
    "      y_train = df_train_y.copy().values.ravel()\n",
    "\n",
    "      predictions = cross_val_predict(pipeline, X_train, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "      mse = mean_squared_error(y_train, predictions)\n",
    "      total_mses += mse\n",
    "    \n",
    "    return total_mses / len(valid_tickers)\n",
    "  except TimeoutException:\n",
    "      print(\"A timeout has occurred during model fitting.\")\n",
    "      # Return a large MSE value to penalize this result\n",
    "      return float('inf')\n",
    "\n",
    "\n",
    "n_columns = len(df_train_X_all[0].columns)\n",
    "# Assuming n_trials is defined elsewhere in your code\n",
    "#study = optuna.create_study(study_name=f'svr_regression_n_columns_{n_columns}', direction='minimize', \n",
    "#      storage=\"mysql://root@192.168.2.34:3306/mysql\",load_if_exists=True) # Ensure that we are minimizing MSE.\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_svm, n_trials=50) # Adjust the number of trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 7,\n",
       " 'C': 57.114656399893754,\n",
       " 'epsilon': 0.024752738576212154,\n",
       " 'kernel': 'poly',\n",
       " 'gamma': 0.00013185446777139358}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the test error on RR.L\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RR.L MSE: 0.20369535025052965\n",
      "Computing the test error on MUV2.DE\n",
      "Test MUV2.DE MSE: 0.02552005332665656\n",
      "Computing the test error on DVA\n",
      "Test DVA MSE: 0.04597833113393158\n",
      "Computing the test error on CTAS\n",
      "Test CTAS MSE: 0.025794384865773113\n",
      "Computing the test error on CCL\n",
      "Test CCL MSE: 0.2290986038802209\n",
      "Computing the test error on ABT\n",
      "Test ABT MSE: 0.01341512478394536\n",
      "Computing the test error on PSON.L\n",
      "Test PSON.L MSE: 0.049357976399516654\n",
      "Computing the test error on SWKS\n",
      "Test SWKS MSE: 0.055788457443848256\n",
      "Computing the test error on ITRK.L\n",
      "Test ITRK.L MSE: 0.03252326891072102\n",
      "average mse: 0.07568572788834922\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "best_params = study.best_params\n",
    "# rebuild the pipeline\n",
    "best_pipeline = Pipeline([\n",
    "        ('truncate', SelectKBest(f_regression, k=best_params['k'])), # Adjust 'k' as needed\n",
    "        ('regress', SafeSVR(C=best_params['C'], \n",
    "            epsilon=best_params['epsilon'], kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] , timeout=60))])\n",
    "\n",
    "mses = []\n",
    "all_errors = None\n",
    "\n",
    "for i in range(len(valid_tickers)):\n",
    "#for i in range(10):\n",
    "  stock_name = valid_tickers[i]\n",
    "  print(f'Computing the test error on {stock_name}')\n",
    "  df_train_X = df_train_X_all[i]\n",
    "  df_train_y = df_train_y_all[i]\n",
    "  df_test_X = df_test_X_all[i]\n",
    "  df_test_y = df_test_y_all[i]\n",
    "\n",
    "  X_train = df_train_X.copy().values\n",
    "  y_train = df_train_y.copy().values.ravel()\n",
    "  X_test = df_test_X.copy().values\n",
    "  y_test = df_test_y.copy().values.ravel()\n",
    "\n",
    "  best_pipeline.fit(X_train, y_train)\n",
    "  y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  print(f'Test {valid_tickers[i]} MSE: {mse}')\n",
    "  mses.append(mse)\n",
    "\n",
    "print('average mse:', np.mean(mses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std mse: 0.07130025118844463\n"
     ]
    }
   ],
   "source": [
    "print('std mse:', np.std(mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-13 05:36:43,631] A new study created in memory with name: no-name-871a2092-43c4-4485-b2e8-c0987dc18b52\n",
      "/tmp/ipykernel_2423564/2461275156.py:60: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.8)\n",
      "[W 2024-05-13 05:39:45,126] Trial 0 failed with parameters: {'k': 38, 'num_layers': 2, 'n_units_l0': 9, 'n_units_l1': 8, 'batch_size': 94, 'dropout_rate': 0.5545291009563955, 'weight_decay': 0.004325933551466524, 'lr': 0.0011000654390328542, 'epochs': 31} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2423564/2461275156.py\", line 110, in objective_ann\n",
      "    train_ann_model(model, train_loader, criterion, optimizer, num_epochs, device)\n",
      "  File \"/tmp/ipykernel_2423564/2461275156.py\", line 36, in train_ann_model\n",
      "    outputs = model(batch_features)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2423564/2461275156.py\", line 24, in forward\n",
      "    return self.layers(x)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ken/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-05-13 05:39:45,127] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 123\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Assuming valid_tickers, df_train_X_all, and df_train_y_all are defined elsewhere in your code\u001b[39;00m\n\u001b[1;32m    122\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Ensure that we are minimizing MSE.\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_ann\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Adjust the number of trials\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[145], line 110\u001b[0m, in \u001b[0;36mobjective_ann\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    107\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[43mtrain_ann_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation fold\u001b[39;00m\n\u001b[1;32m    113\u001b[0m mse \u001b[38;5;241m=\u001b[39m evaluate_ann_model(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[145], line 36\u001b[0m, in \u001b[0;36mtrain_ann_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), batch_labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[145], line 24\u001b[0m, in \u001b[0;36mANN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/stock/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the ANN as a PyTorch module\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size=1, dropout_rate=0.5):\n",
    "        super(ANN, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_layers)):\n",
    "            layers.append(nn.Linear(input_size if i == 0 else hidden_layers[i - 1], hidden_layers[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:  # Add dropout if dropout_rate is greater than 0\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_layers[-1], output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def train_ann_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            # Move data to device\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "            # Zero out gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(batch_features)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.squeeze(), batch_labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate_ann_model(model, train_loader, device):\n",
    "    model.eval()\n",
    "    predictions, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            batch_features = batch_features.to(device)\n",
    "            outputs = model(batch_features)\n",
    "            predictions.extend(outputs.view(-1).cpu().tolist())  # Ensure outputs are flattened\n",
    "            targets.extend(batch_labels.cpu().tolist())\n",
    "    return mean_squared_error(targets, predictions)\n",
    "\n",
    "def objective_ann(trial):\n",
    "    # Define the hyperparameter configuration space\n",
    "    k = trial.suggest_int('k', len(df_train_X_all[0].columns)-1, len(df_train_X_all[0].columns))\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    hidden_layers = [trial.suggest_int('n_units_l{}'.format(i), 4, 16) for i in range(num_layers)]\n",
    "    batch_size = trial.suggest_int('batch_size', 64, 128)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.8)\n",
    "    # Add penalty term to hyperparameters\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-1, log=True)\n",
    "    learning_rate = trial.suggest_float('lr', 5e-5, 1e-1, log=True)\n",
    "    num_epochs = trial.suggest_int('epochs', 20, 50)\n",
    "    n_splits = 5  # Number of folds in K-fold cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "\n",
    "    # Check if a GPU is available and set the device accordingly\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    total_mses = 0\n",
    "    for i in range(len(valid_tickers)):\n",
    "        df_train_X = df_train_X_all[i]\n",
    "        df_train_y = df_train_y_all[i]\n",
    "        \n",
    "        # Create feature selector (this will be refitted in each fold)\n",
    "        selector = SelectKBest(f_regression, k=k)\n",
    "\n",
    "        # Perform K-fold cross-validation\n",
    "        mses = []\n",
    "        for train_index, val_index in kf.split(df_train_X):\n",
    "            X_train_fold = df_train_X.values[train_index]\n",
    "            y_train_fold = df_train_y.values[train_index].ravel()\n",
    "            X_val_fold = df_train_X.values[val_index]\n",
    "            y_val_fold = df_train_y.values[val_index].ravel()\n",
    "\n",
    "            # Apply feature selection\n",
    "            X_train_fold_selected = selector.fit_transform(X_train_fold, y_train_fold)\n",
    "            X_val_fold_selected = selector.transform(X_val_fold)\n",
    "            \n",
    "            # Convert to PyTorch tensors and move to the current device\n",
    "            train_dataset = TensorDataset(torch.tensor(X_train_fold_selected, dtype=torch.float32).to(device),\n",
    "                                          torch.tensor(y_train_fold, dtype=torch.float32).to(device))\n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            val_dataset = TensorDataset(torch.tensor(X_val_fold_selected, dtype=torch.float32).to(device),\n",
    "                                        torch.tensor(y_val_fold, dtype=torch.float32).to(device))\n",
    "            val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            # Instantiate the ANN\n",
    "            model = ANN(input_size=X_train_fold_selected.shape[1], \n",
    "                hidden_layers=hidden_layers, \n",
    "                dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "            # Loss and optimizer\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "            # Train the model\n",
    "            train_ann_model(model, train_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "            # Evaluate the model on the validation fold\n",
    "            mse = evaluate_ann_model(model, val_loader, device)\n",
    "            mses.append(mse)\n",
    "\n",
    "        # Average Mean Squared Error across all folds for the current ticker\n",
    "        total_mses += np.mean(mses)\n",
    "    \n",
    "    return total_mses / len(valid_tickers)\n",
    "\n",
    "# Assuming valid_tickers, df_train_X_all, and df_train_y_all are defined elsewhere in your code\n",
    "study = optuna.create_study(direction='minimize') # Ensure that we are minimizing MSE.\n",
    "study.optimize(objective_ann, n_trials=3) # Adjust the number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 14,\n",
       " 'num_layers': 2,\n",
       " 'n_units_l0': 30,\n",
       " 'n_units_l1': 17,\n",
       " 'batch_size': 111,\n",
       " 'dropout_rate': 0.20976011844996184,\n",
       " 'weight_decay': 0.00014366498611745817,\n",
       " 'lr': 0.0014266952019914144,\n",
       " 'epochs': 35}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RR.L MSE: 0.2088548326592732\n",
      "Test MUV2.DE MSE: 0.028592081792217724\n",
      "Test DVA MSE: 0.04754702194769223\n",
      "Test CTAS MSE: 0.07911319789912107\n",
      "Test CCL MSE: 0.19111456430426219\n",
      "Test ABT MSE: 0.03453646470841689\n",
      "Test PSON.L MSE: 0.06878608028586863\n",
      "Test SWKS MSE: 0.31823372140258116\n",
      "Test ITRK.L MSE: 0.1034700175410375\n",
      "0.12002755361560784\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "k=best_params['k']\n",
    "batch_size = best_params['batch_size']\n",
    "lr = best_params['lr']\n",
    "num_epochs = best_params['epochs']\n",
    "num_layers = best_params['num_layers']\n",
    "\n",
    "hidden_layers = [best_params[f'n_units_l{i}'] for i in range(num_layers)]\n",
    "selector = SelectKBest(f_regression, k=k)\n",
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mses = []\n",
    "for i in range(len(valid_tickers)):\n",
    "  df_train_X = df_train_X_all[i]\n",
    "  df_train_y = df_train_y_all[i]\n",
    "  df_test_X = df_test_X_all[i]\n",
    "  df_test_y = df_test_y_all[i]\n",
    "\n",
    "  X_train = df_train_X.copy().values\n",
    "  y_train = df_train_y.copy().values.ravel()\n",
    "  X_test = df_test_X.copy().values\n",
    "  y_test = df_test_y.copy().values.ravel()\n",
    "\n",
    "  X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "  X_test_selected = selector.transform(X_test)\n",
    "  \n",
    "  model = ANN(input_size=X_train_selected.shape[1], hidden_layers=hidden_layers).to(device)\n",
    "\n",
    "\n",
    "\n",
    "  train_dataset = TensorDataset(torch.tensor(X_train_selected, dtype=torch.float32).to(device),\n",
    "                                torch.tensor(y_train, dtype=torch.float32).to(device))\n",
    "  train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  test_dataset = TensorDataset(torch.tensor(X_test_selected, dtype=torch.float32).to(device),\n",
    "                              torch.tensor(y_test, dtype=torch.float32).to(device))\n",
    "  test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "  # Train the model\n",
    "\n",
    "  # Loss and optimizer\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "  train_ann_model(model, train_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "  # Evaluate the model on the validation fold\n",
    "  mse = evaluate_ann_model(model, test_loader, device)\n",
    "  print(f'Test {valid_tickers[i]} MSE: {mse}')\n",
    "\n",
    "  mses.append(mse)\n",
    "\n",
    "print(np.mean(mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if study.best_value < best_value:\n",
    "  best_value = study.best_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "best_params = study.best_params\n",
    "# rebuild the pipeline\n",
    "best_pipeline = Pipeline([\n",
    "        ('truncate', SelectKBest(f_regression, k=best_params['k'])), # Adjust 'k' as needed\n",
    "        ('regress', SafeRandomForestRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        min_samples_split=best_params['min_samples_split'],\n",
    "        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "        max_features=best_params['max_features'],\n",
    "        bootstrap=best_params['bootstrap'],\n",
    "        max_leaf_nodes=best_params['max_leaf_nodes']\n",
    "    ))])\n",
    "\n",
    "# get current date\n",
    "cur_date = datetime.now().strftime('%m%d%y')\n",
    "model_dir = f'models/model_{cur_date}'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save to file in the current working directory\n",
    "with open(f\"{model_dir}/best_pipeline.pkl\", \"wb\") as file:  \n",
    "    pickle.dump(best_pipeline, file)\n",
    "\n",
    "# save the valid_tickers in a text file under the directory\n",
    "with open(f'{model_dir}/valid_tickers.txt', 'w') as f:\n",
    "    for ticker in valid_tickers:\n",
    "        f.write(\"%s\\n\" % ticker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_X(stock_name, start='2018-01-01'):        \n",
    "  df = load_latest_price_data(stock_name)\n",
    "  df, feature_columns = add_features(df, 10)\n",
    "  timestamp = df.index[0]\n",
    "  earliest_date = timestamp.strftime('%Y-%m-%d')\n",
    "  start = earliest_date\n",
    "  end = None\n",
    "\n",
    "  df, columns = merge_fred(df, 'M2SL', 6, start, end, 4, 2, if_log=True)\n",
    "  \n",
    "  feature_columns += columns\n",
    "  df, columns = merge_fred(df, 'UNRATE', 6, start, end, 1, 5, if_log=False)\n",
    "  feature_columns += columns\n",
    "\n",
    "  df, columns = merge_fred(df, 'FEDFUNDS', 6, start, end, 1, 5, if_log=False)\n",
    "  feature_columns += columns\n",
    "  df, _ = remove_nan(df, type='top')\n",
    "  df_predict_X = df[feature_columns]\n",
    "  \n",
    "  return df_predict_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the test error on RR.L\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'rf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Get predictions from each individual tree\u001b[39;00m\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m best_pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregress\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 41\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([tree\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrf\u001b[49m\u001b[38;5;241m.\u001b[39mestimators_])\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m df_std_preditions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mstd(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), index\u001b[38;5;241m=\u001b[39mdf_test_y\u001b[38;5;241m.\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39m[stock_name])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'rf'"
     ]
    }
   ],
   "source": [
    "# Best parameters and model\n",
    "\n",
    "\n",
    "\n",
    "mse_rf = []\n",
    "all_errors = None\n",
    "\n",
    "\n",
    "# the mean of standard deviation of predictions, mean_var_predictions[0] is a number indicating the mean of variance of predictions of the first stock\n",
    "mean_var_predictions = []\n",
    "# the multiplier which is cov(var_predictions, mse)/var(std_predictions)\n",
    "# during inferencing, the conditional expected error is calculated with:\n",
    "# E[errors|std_predictions=std] = mean_errors[i] + multiplier*(std-mean_std_predictions[i]) when \n",
    "multiplier = []\n",
    "exp_profits = []\n",
    "predict_stds = []\n",
    "for i in range(len(valid_tickers)):\n",
    "#for i in range(10):\n",
    "\n",
    "  stock_name = valid_tickers[i]\n",
    "  print(f'Computing the test error on {stock_name}')\n",
    "  df_train_X = df_train_X_all[i]\n",
    "  df_train_y = df_train_y_all[i]\n",
    "  df_test_X = df_test_X_all[i]\n",
    "  df_test_y = df_test_y_all[i]\n",
    "\n",
    "  X_train = df_train_X.copy().values\n",
    "  y_train = df_train_y.copy().values.ravel()\n",
    "  X_test = df_test_X.copy().values\n",
    "  y_test = df_test_y.copy().values.ravel()\n",
    "\n",
    "  best_pipeline.fit(X_train, y_train)\n",
    "  y_pred = best_pipeline.predict(X_test)\n",
    "  X_test_tranformed = X_test\n",
    "\n",
    "  \n",
    "  for name, step in best_pipeline.steps[:-1]:\n",
    "    X_test_tranformed = step.transform(X_test_tranformed)\n",
    "  # Get predictions from each individual tree\n",
    "  model = best_pipeline.named_steps['regress']\n",
    "  predictions = np.array([tree.predict(X_test) for tree in model.rf.estimators_])\n",
    "  \n",
    "  print(f'predictions shape: {predictions.shape}')\n",
    "  df_std_preditions = pd.DataFrame(np.std(predictions, axis=0), index=df_test_y.index, columns=[stock_name])\n",
    "  print(f'predictions std shape: {df_std_preditions.shape}')\n",
    "  # reuse the index of df_test_y and the value of y_pred to create a new dataframe\n",
    "  df_error = pd.DataFrame(y_pred - y_test, index=df_test_y.index, columns=[stock_name])\n",
    "  print('mean error:', df_error.mean())\n",
    "\n",
    "  # calculate the correlation between std_predictions and errors, this should be a single value\n",
    "  correlation = df_std_preditions.corrwith(np.abs(df_error), axis=0).values[0]\n",
    "  print(f'Correlation between std_predictions and errors: {correlation}')\n",
    "\n",
    "\n",
    "  if all_errors is None:\n",
    "    all_errors = df_error\n",
    "  else:\n",
    "    # concatenate the new dataframe to the existing one, column wise, use outer approach\n",
    "    all_errors = pd.concat([all_errors, df_error], axis=1, join='outer')\n",
    "\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  print(f'Test {valid_tickers[i]} MSE: {mse}')\n",
    "  mse_rf.append(mse)\n",
    "\n",
    "\n",
    "  # make the prediction\n",
    " \n",
    "  df_predict_X = get_predict_X(stock_name)\n",
    "  \n",
    "  X_predict = df_predict_X.copy().values\n",
    "\n",
    "  y_pred_2 = best_pipeline.predict(X_predict)\n",
    "  predictions = np.array([tree.predict(X_predict) for tree in model.rf.estimators_])\n",
    "  std_predictions = np.std(predictions, axis=0)\n",
    "\n",
    "  # the last prediction\n",
    "  profit = y_pred_2[-1]\n",
    "\n",
    "  # the last std of predictions.\n",
    "  predict_std = std_predictions[-1]\n",
    "  adj_profit = profit - df_error.mean().values[0]\n",
    "  print(f'Computing the latest expected profit on {stock_name}, profit={profit}, adjusted_profit={adj_profit}')\n",
    "  exp_profits.append(adj_profit)\n",
    "  predict_stds.append(predict_std)\n",
    "\n",
    "all_errors.to_csv('data/intermediate_results/all_errors.csv')\n",
    "exp_profits = np.array(exp_profits)\n",
    "# save the exp_profits\n",
    "np.save('data/intermediate_results/exp_profits.npy', exp_profits)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38683161503216024,\n",
       " 0.12192519660519724,\n",
       " 0.15901024390225854,\n",
       " 0.10322441871369688,\n",
       " 0.10871496012956741,\n",
       " 0.14363130779679428,\n",
       " 0.05979100661046735,\n",
       " 0.04607490798814773,\n",
       " 0.28951094608153743,\n",
       " 0.08359559906888177,\n",
       " 0.07654655506441961,\n",
       " 0.05562019332730785,\n",
       " 0.31704379279918227,\n",
       " 0.30679561937713773,\n",
       " 0.10972473645469441,\n",
       " 0.1619843647826151,\n",
       " 0.03209714163456427,\n",
       " 0.1211781056967604,\n",
       " 0.4089114612957843,\n",
       " 0.2540948301600203,\n",
       " 0.09195080595405253,\n",
       " 0.225949260082828,\n",
       " 0.07710528129683611,\n",
       " 0.1099416686963243,\n",
       " 0.23678250557520578,\n",
       " 0.05674455825123386,\n",
       " 0.1377717835717175,\n",
       " 0.09607781626136751,\n",
       " 0.047194052906656896,\n",
       " 0.12623446256703233,\n",
       " 0.06370017337891494,\n",
       " 0.047983872599328625,\n",
       " 0.09473363981623815,\n",
       " 0.14482266487620793,\n",
       " 0.17945887642689765,\n",
       " 0.15627287408501253,\n",
       " 0.22001950595442885,\n",
       " 0.09647217399302173,\n",
       " 0.16506865294107556,\n",
       " 0.0963228839383368,\n",
       " 0.1391431763473572,\n",
       " 0.13778961792498676,\n",
       " 0.10567728190014451,\n",
       " 0.1446211115003834,\n",
       " 0.10455952681305099,\n",
       " 0.16509071367003803,\n",
       " 0.07260092853533151,\n",
       " 0.08943963283561655,\n",
       " 0.11671400762956463,\n",
       " 0.15127705494848198,\n",
       " 0.1200509843872381,\n",
       " 0.029949083487097676,\n",
       " 0.05184586664906163,\n",
       " 0.06417417103149269,\n",
       " 0.3376938851533161,\n",
       " 0.24318357088041698,\n",
       " 0.1225522665267799,\n",
       " 0.0864276344249361,\n",
       " 0.16559242582978206,\n",
       " 0.7171971662017085,\n",
       " 0.1803648713836371,\n",
       " 0.0919337499589884,\n",
       " 0.10508330510769885,\n",
       " 0.28979637733024016,\n",
       " 0.22879754860946444,\n",
       " 0.2598305866233395,\n",
       " 0.7171971662017085,\n",
       " 0.06846808486253436,\n",
       " 0.13217214152728243,\n",
       " 0.045515397576215144,\n",
       " 0.1161098372382451,\n",
       " 0.11587174811680635,\n",
       " 0.04780200055558835,\n",
       " 0.13876963434408188,\n",
       " 0.04795606027047418,\n",
       " 0.13265568965555766,\n",
       " 0.1177568030739463,\n",
       " 0.154584888539439,\n",
       " 0.10931624844051187,\n",
       " 0.12285782408982576,\n",
       " 0.2945713129246422,\n",
       " 0.1258374999804131,\n",
       " 0.042408604766394055,\n",
       " 0.059369200885787836,\n",
       " 0.16653683056153754,\n",
       " 0.18449377582822912,\n",
       " 0.15954322611140778,\n",
       " 0.10477681713543364,\n",
       " 0.15572807107865805,\n",
       " 0.09314743434004533,\n",
       " 0.19320471573086098,\n",
       " 0.1662639345939656,\n",
       " 0.10418795493111062,\n",
       " 0.1693800677968408,\n",
       " 0.12161152244684285,\n",
       " 0.1188576414270363,\n",
       " 0.1661473944318547,\n",
       " 0.14050942177856585,\n",
       " 0.25431909791715834,\n",
       " 0.10091617098098936,\n",
       " 0.10924152471736537,\n",
       " 0.2137387444752038,\n",
       " 0.10847918904687308,\n",
       " 0.10195498187932196,\n",
       " 0.14581710106950907]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# You can load it back into memory with the following code\n",
    "with open(\"data/intermediate_results/best_pipeline.pkl\", \"rb\") as file:  \n",
    "    loaded_pipeline = pickle.load(file)\n",
    " \n",
    "# Test that it loaded back correctly\n",
    "best_pipeline = loaded_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;truncate&#x27;,\n",
       "                 SelectKBest(k=38,\n",
       "                             score_func=&lt;function f_regression at 0x7fa3edcc5a80&gt;)),\n",
       "                (&#x27;regress&#x27;,\n",
       "                 SafeRandomForestRegressor(max_depth=33, max_features=&#x27;log2&#x27;,\n",
       "                                           max_leaf_nodes=12,\n",
       "                                           min_samples_split=4,\n",
       "                                           n_estimators=55))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;truncate&#x27;,\n",
       "                 SelectKBest(k=38,\n",
       "                             score_func=&lt;function f_regression at 0x7fa3edcc5a80&gt;)),\n",
       "                (&#x27;regress&#x27;,\n",
       "                 SafeRandomForestRegressor(max_depth=33, max_features=&#x27;log2&#x27;,\n",
       "                                           max_leaf_nodes=12,\n",
       "                                           min_samples_split=4,\n",
       "                                           n_estimators=55))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=38, score_func=&lt;function f_regression at 0x7fa3edcc5a80&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SafeRandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>SafeRandomForestRegressor(max_depth=33, max_features=&#x27;log2&#x27;, max_leaf_nodes=12,\n",
       "                          min_samples_split=4, n_estimators=55)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('truncate',\n",
       "                 SelectKBest(k=38,\n",
       "                             score_func=<function f_regression at 0x7fa3edcc5a80>)),\n",
       "                ('regress',\n",
       "                 SafeRandomForestRegressor(max_depth=33, max_features='log2',\n",
       "                                           max_leaf_nodes=12,\n",
       "                                           min_samples_split=4,\n",
       "                                           n_estimators=55))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07026743832443463\n",
      "0.03080702658342465\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mse_rf))\n",
    "print(np.std(mse_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04478618892632091\n",
      "0.04483087917609076\n",
      "0.04487071591455632\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mses['mse_1']))\n",
    "print(np.mean(mses['mse_3']))\n",
    "print(np.mean(mses['mse_5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start portfolio optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def portfolio_volatility(weights, covariance):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(covariance, weights)))\n",
    "\n",
    "def portfolio_return(weights, returns):\n",
    "    return np.sum(returns*weights)\n",
    "\n",
    "def min_func_sharpe(weights, returns, covariance):\n",
    "    return -portfolio_return(weights, returns) / portfolio_volatility(weights, covariance)\n",
    "\n",
    "def optimize_portfolio(returns, covariance):\n",
    "    num_assets = len(returns)\n",
    "    args = (returns, covariance)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "    result = minimize(min_func_sharpe, num_assets*[1./num_assets,], args=args,\n",
    "                                method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2423564/2623600917.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  S = get_shrinkage_covariance(all_errors.fillna(method='ffill').fillna(method='bfill'))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "def get_shrinkage_covariance(df):\n",
    "    lw = LedoitWolf(store_precision=False, assume_centered=True)\n",
    "    lw.fit(df)\n",
    "    # Convert the ndarray back to a DataFrame and use the column and index from the original DataFrame\n",
    "    shrink_cov = pd.DataFrame(lw.covariance_, index=df.columns, columns=df.columns)\n",
    "    return shrink_cov\n",
    "\n",
    "S = get_shrinkage_covariance(all_errors.fillna(method='ffill').fillna(method='bfill'))\n",
    "#S = all_errors.cov()\n",
    "#S = CovarianceShrinkage(all_errors).ledoit_wolf()\n",
    "mu = exp_profits\n",
    "raw_weights = optimize_portfolio(mu, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMUS</th>\n",
       "      <th>DVA</th>\n",
       "      <th>LEN</th>\n",
       "      <th>SWKS</th>\n",
       "      <th>PSON.L</th>\n",
       "      <th>COF</th>\n",
       "      <th>CTAS</th>\n",
       "      <th>BMW.DE</th>\n",
       "      <th>POOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TMUS</th>\n",
       "      <td>0.102787</td>\n",
       "      <td>-0.011414</td>\n",
       "      <td>0.048833</td>\n",
       "      <td>0.022699</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.030775</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.026588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVA</th>\n",
       "      <td>-0.011414</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>-0.017447</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>-0.008509</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.037075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEN</th>\n",
       "      <td>0.048833</td>\n",
       "      <td>-0.017447</td>\n",
       "      <td>0.083211</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>0.018169</td>\n",
       "      <td>0.056146</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>0.035047</td>\n",
       "      <td>0.029097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWKS</th>\n",
       "      <td>0.022699</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>-0.004601</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.020484</td>\n",
       "      <td>0.031542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSON.L</th>\n",
       "      <td>0.017751</td>\n",
       "      <td>-0.008509</td>\n",
       "      <td>0.018169</td>\n",
       "      <td>-0.004601</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>-0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COF</th>\n",
       "      <td>0.030775</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.056146</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.112880</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>0.042221</td>\n",
       "      <td>0.037042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTAS</th>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>0.025670</td>\n",
       "      <td>0.014887</td>\n",
       "      <td>0.021574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW.DE</th>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.035047</td>\n",
       "      <td>0.020484</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>0.042221</td>\n",
       "      <td>0.014887</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.018203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POOL</th>\n",
       "      <td>0.026588</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.029097</td>\n",
       "      <td>0.031542</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.037042</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>0.018203</td>\n",
       "      <td>0.052913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TMUS       DVA       LEN      SWKS    PSON.L       COF      CTAS  \\\n",
       "TMUS    0.102787 -0.011414  0.048833  0.022699  0.017751  0.030775  0.006338   \n",
       "DVA    -0.011414  0.109467 -0.017447  0.046579 -0.008509  0.029859  0.008897   \n",
       "LEN     0.048833 -0.017447  0.083211  0.017286  0.018169  0.056146  0.022878   \n",
       "SWKS    0.022699  0.046579  0.017286  0.058144 -0.004601  0.035150  0.013535   \n",
       "PSON.L  0.017751 -0.008509  0.018169 -0.004601  0.044233  0.035538  0.008694   \n",
       "COF     0.030775  0.029859  0.056146  0.035150  0.035538  0.112880  0.028816   \n",
       "CTAS    0.006338  0.008897  0.022878  0.013535  0.008694  0.028816  0.025670   \n",
       "BMW.DE  0.012989  0.008211  0.035047  0.020484  0.013117  0.042221  0.014887   \n",
       "POOL    0.026588  0.037075  0.029097  0.031542 -0.001246  0.037042  0.021574   \n",
       "\n",
       "          BMW.DE      POOL  \n",
       "TMUS    0.012989  0.026588  \n",
       "DVA     0.008211  0.037075  \n",
       "LEN     0.035047  0.029097  \n",
       "SWKS    0.020484  0.031542  \n",
       "PSON.L  0.013117 -0.001246  \n",
       "COF     0.042221  0.037042  \n",
       "CTAS    0.014887  0.021574  \n",
       "BMW.DE  0.039604  0.018203  \n",
       "POOL    0.018203  0.052913  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(raw_weights.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 TMUS: weight 0.24928816453966893 exp profit: 0.17436708924700098, variance: 0.10278736819495185, std_predictions: 0.31987970703493285\n",
      "index: 1 DVA: weight 0.2337177786463047 exp profit: 0.18165408729091437, variance: 0.10946672053061961, std_predictions: 0.49740245377752645\n",
      "index: 6 CTAS: weight 0.5169940568140263 exp profit: 0.11252118030471515, variance: 0.025670261638506563, std_predictions: 0.09120038599247159\n"
     ]
    }
   ],
   "source": [
    "def adjust_weights(weights, threshold=0.05):\n",
    "    new_weights = np.array(weights)\n",
    "    # Identify weights below the threshold\n",
    "    below_threshold = weights < threshold\n",
    "    # Set these weights to 0\n",
    "    new_weights[below_threshold] = 0\n",
    "    # Compute the deficit (i.e., how much we are currently missing to get to a total of 1)\n",
    "    deficit = 1 - np.sum(new_weights)\n",
    "    # Spread this deficit equally among the remaining stocks (i.e., the ones with weights > 0.05)\n",
    "    new_weights[~below_threshold] += deficit / np.sum(~below_threshold)\n",
    "    return new_weights\n",
    "\n",
    "adjusted_weights = adjust_weights(raw_weights.x)\n",
    "tickers_to_buy = []\n",
    "tickers_to_buy_idx = []\n",
    "for index, ticker_name in enumerate(valid_tickers):\n",
    "   adjusted_weight = adjusted_weights[index]\n",
    "   if adjusted_weight > 0:\n",
    "      print(f'index: {index} {ticker_name}: weight {adjusted_weight} exp profit: {exp_profits[index]}, variance: {S[ticker_name][ticker_name]}, std_predictions: {predict_stds[index]}')\n",
    "      tickers_to_buy.append(ticker_name)\n",
    "      tickers_to_buy_idx.append(index)\n",
    "   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09139265868439626"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(exp_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# number of simulations\n",
    "num_portfolios = 1000\n",
    "risk_free_rate = 0.02  # assuming a risk-free rate of 1%\n",
    "valid_tickers = valid_tickers\n",
    "expected_returns = mu\n",
    "covariance_matrix = S\n",
    "optimized_weights = adjusted_weights\n",
    "# pre-allocating space for each simulation's return and standard deviation\n",
    "port_returns = np.zeros(num_portfolios)\n",
    "port_volatility = np.zeros(num_portfolios)\n",
    "sharpe_ratio = np.zeros(num_portfolios)\n",
    "\n",
    "for i in range(num_portfolios):\n",
    "    weights = np.random.random(len(expected_returns))\n",
    "    weights /= np.sum(weights)\n",
    "    port_returns[i] = np.sum(expected_returns * weights)\n",
    "    port_volatility[i] = np.sqrt(np.dot(weights.T, np.dot(covariance_matrix, weights)))\n",
    "    sharpe_ratio[i] = (port_returns[i] - risk_free_rate) / port_volatility[i]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(port_volatility, port_returns, c=sharpe_ratio, cmap='viridis')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "\n",
    "index_high_sharpe = np.argmax(sharpe_ratio)\n",
    "plt.scatter(port_volatility[index_high_sharpe], port_returns[index_high_sharpe], c='red', s=50)\n",
    "\n",
    "\n",
    "\n",
    "for index in tickers_to_buy_idx:\n",
    "    ticker_name = valid_tickers[index]\n",
    "    x = np.sqrt(S[ticker_name][ticker_name])\n",
    "    y = exp_profits[index]\n",
    "    plt.scatter(x, y, c='blue', s=50)\n",
    "    plt.text(x, y, ticker_name, fontsize=9)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.59622916186161\n",
      "0.05066177710759178\n"
     ]
    }
   ],
   "source": [
    "print(portfolio_return(adjusted_weights, mu))\n",
    "print(portfolio_volatility(adjusted_weights, S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6000572 ],\n",
       "       [ 0.00328448],\n",
       "       [ 0.24460852],\n",
       "       [ 0.04439486],\n",
       "       [ 0.15531322],\n",
       "       [ 0.18533133],\n",
       "       [ 0.04915312],\n",
       "       [ 0.12223531],\n",
       "       [ 0.21267194],\n",
       "       [ 0.06521123],\n",
       "       [-0.01302115],\n",
       "       [ 0.08681719],\n",
       "       [ 0.26876473],\n",
       "       [ 0.27925998],\n",
       "       [-0.06266544],\n",
       "       [ 0.40393339],\n",
       "       [ 0.07791322],\n",
       "       [ 0.06647406],\n",
       "       [ 0.39877872],\n",
       "       [ 0.32789263],\n",
       "       [ 0.1488702 ],\n",
       "       [ 0.20966391],\n",
       "       [-0.04255854],\n",
       "       [-0.05606025],\n",
       "       [-0.03997648],\n",
       "       [ 0.10393165],\n",
       "       [ 0.11601928],\n",
       "       [-0.0164272 ],\n",
       "       [ 0.05609233],\n",
       "       [ 0.08287344],\n",
       "       [-0.00815096],\n",
       "       [ 0.12911717],\n",
       "       [ 0.11104052],\n",
       "       [ 0.01359091],\n",
       "       [-0.00622627],\n",
       "       [ 0.06269222],\n",
       "       [ 0.00096797],\n",
       "       [-0.01542905],\n",
       "       [ 0.11238722],\n",
       "       [ 0.13931198],\n",
       "       [ 0.16965317],\n",
       "       [ 0.15981081],\n",
       "       [-0.02901215],\n",
       "       [ 0.00319639],\n",
       "       [ 0.10467948],\n",
       "       [ 0.05205115],\n",
       "       [ 0.02382013],\n",
       "       [ 0.03791093],\n",
       "       [ 0.41672894],\n",
       "       [ 0.22749866],\n",
       "       [-0.23554305],\n",
       "       [ 0.03108053],\n",
       "       [ 0.14632164],\n",
       "       [ 0.0562887 ],\n",
       "       [ 0.52676117],\n",
       "       [ 0.06898162],\n",
       "       [-0.0614259 ],\n",
       "       [ 0.07997715],\n",
       "       [ 0.0102416 ],\n",
       "       [ 0.68728342],\n",
       "       [-0.14295363],\n",
       "       [ 0.06144334],\n",
       "       [ 0.06688593],\n",
       "       [-0.16676045],\n",
       "       [ 0.15591293],\n",
       "       [ 0.09845397],\n",
       "       [ 0.68728342],\n",
       "       [ 0.10937193],\n",
       "       [ 0.02133109],\n",
       "       [-0.00301773],\n",
       "       [ 0.03757547],\n",
       "       [ 0.01697184],\n",
       "       [-0.0611857 ],\n",
       "       [ 0.00831793],\n",
       "       [ 0.00328501],\n",
       "       [ 0.07065865],\n",
       "       [ 0.09468858],\n",
       "       [ 0.02899207],\n",
       "       [ 0.10332807],\n",
       "       [-0.08205035],\n",
       "       [ 0.09162956],\n",
       "       [-0.09974774],\n",
       "       [-0.02823799],\n",
       "       [-0.04783438],\n",
       "       [-0.04101751],\n",
       "       [ 0.14672217],\n",
       "       [ 0.11854735],\n",
       "       [-0.00296397],\n",
       "       [-0.03449873],\n",
       "       [-0.00352877],\n",
       "       [ 0.12079566],\n",
       "       [ 0.13699742],\n",
       "       [ 0.02393071],\n",
       "       [-0.0008337 ],\n",
       "       [ 0.23187209],\n",
       "       [ 0.06679118],\n",
       "       [ 0.07166306],\n",
       "       [ 0.08138886],\n",
       "       [ 0.03769237],\n",
       "       [ 0.07794508],\n",
       "       [-0.04046879],\n",
       "       [ 0.10390463],\n",
       "       [ 0.07242889],\n",
       "       [ 0.12245016],\n",
       "       [ 0.18762625]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
